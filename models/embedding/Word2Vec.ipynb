{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a37f96-8da6-43df-828c-8a10fd956cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import unicodedata\n",
    "\n",
    "from botok import BoString\n",
    "from botok.vars import CharMarkers\n",
    "from openpecha.corpus.download import download_corpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import config\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc7147-2c04-4a9b-9e80-68e4a030a832",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aec154a1-ba92-43a3-af2e-cae1759e17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    {\"path\": config.DATA_DIR / \"esukhia_katen\", \"pattern\": \"-tokenized\"},  \n",
    "    {\"path\": config.DATA_DIR / \"literary_bo\", \"pattern\": \".txt\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9327829c-975c-4ada-9d5c-584b789e8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(corpus):\n",
    "    for corpus_item in corpus:\n",
    "        for pecha_path in corpus_item[\"path\"].iterdir():\n",
    "            if not pecha_path.is_dir(): continue\n",
    "            for fn in pecha_path.iterdir():\n",
    "                if corpus_item[\"pattern\"] not in fn.name: continue\n",
    "                yield fn\n",
    "            \n",
    "def is_punt(string):\n",
    "    normal_punt = CharMarkers(5)\n",
    "    special_punt = CharMarkers(6)\n",
    "    bo_string = BoString(string)\n",
    "    for _, char_marker_value in bo_string.base_structure.items():\n",
    "        char_maker = CharMarkers(char_marker_value)\n",
    "        if char_maker == normal_punt or char_maker == special_punt:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def preprocess(token):\n",
    "    token = token.replace(\"_\", \"\")\n",
    "    if not token.endswith(\"་\"):\n",
    "        token += \"་\"\n",
    "    return token\n",
    "    \n",
    "def tokenize(text):\n",
    "    return [preprocess(token) for token in text.split() if token and not is_punt(token)]\n",
    "    \n",
    "def get_sentences(files):\n",
    "    for fn in files:\n",
    "        for sentence in fn.open('r'):\n",
    "            if len(sentence.split()) < 3: continue\n",
    "            yield tokenize(unicodedata.normalize(\"NFKC\", sentence.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf45e9-34b3-4508-b1dc-5f9e7f77cb13",
   "metadata": {},
   "source": [
    "### EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9f3156f-41be-4a8b-97cf-42414108692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/studio-lab-user/.models/data/literary_bo/P8B4D67B5/UT3JT13350_018_0000.txt'),\n",
       " PosixPath('/home/studio-lab-user/.models/data/literary_bo/P8B4D67B5/UT3JT13350_019_0000.txt'),\n",
       " PosixPath('/home/studio-lab-user/.models/data/literary_bo/P8B4D67B5/UT3JT13350_020_0000.txt'),\n",
       " PosixPath('/home/studio-lab-user/.models/data/literary_bo/P8B4D67B5/UT3JT13350_021_0000.txt'),\n",
       " PosixPath('/home/studio-lab-user/.models/data/literary_bo/P9E02F6EB/UT3JT13313_001_0000.txt')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(get_files(corpus))\n",
    "files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5cbbebd-4b81-4090-8e7e-495847cdf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randint(0, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14b859c6-178f-4f26-9ff5-95329c028374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "༼_༽ ན་མོ་ རཏྣ་ ཏྲ་ ཡ་ ཡ་ །_ རྒྱལ་སྲིད་ སྤངས་ ན་ དཀའ་བ་ བརྒྱ་ ཕྲག་ གིས་ །_ བླ་མ་ བརྒྱ་ དང་ ལྔ་ བཅུ་ རྩ་ བདུན་ བརྟེན་ །_\n",
      "ཤེས་བྱ་ ཐམས་ཅད་ ཡང་དག་ ཐུགས་ སུ་ ཆུད་ །_\n",
      "རྒྱལ་བ་ ཉིས་་ ར་ གྱུར་ ལ་ གསོལ་བ་ འདེབས་ །_\n",
      "རྒྱལ་བ་ འི་ མདུན་ ན་ རྒྱལ་སྲས་ བཟང་པོ་ སྐྱོང་ །_\n",
      "ཁ་བ་ ཅན་ དུ་ དཔལ་ལྡན་ སྨ་ར་ མེ་ མཇད་ །_ དགའ་ལྡན་ གནས་ སུ་ ནམ་མཁའ་ ཏྲི་ མ་ མེད་ །_\n",
      "ཡིད་བཞིན་ ནོར་བུ་ ཁྱེད་ ལ་ གསོལ་བ་ འདེབས་ །_\n",
      "སྒྲོལ་མ་ ས་ ལུང་བསྟན་ རྒྱལ་བུ་ དཀོན་མཆོག་ འབང་ །_ ཐུབ་བསྟན་ ཡོངས་སུ་ རྫོགས་པ་ འི་ མངའ་བདག་ མཆོག་ ལྷ་ཆོས་ བདུན་ ཇོ་བོ་ བཀ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ན་མོ་',\n",
       " 'རཏྣ་',\n",
       " 'ཏྲ་',\n",
       " 'ཡ་',\n",
       " 'ཡ་',\n",
       " 'རྒྱལ་སྲིད་',\n",
       " 'སྤངས་',\n",
       " 'ན་',\n",
       " 'དཀའ་བ་',\n",
       " 'བརྒྱ་',\n",
       " 'ཕྲག་',\n",
       " 'གིས་',\n",
       " 'བླ་མ་',\n",
       " 'བརྒྱ་',\n",
       " 'དང་',\n",
       " 'ལྔ་',\n",
       " 'བཅུ་',\n",
       " 'རྩ་',\n",
       " 'བདུན་',\n",
       " 'བརྟེན་',\n",
       " 'ཤེས་བྱ་',\n",
       " 'ཐམས་ཅད་',\n",
       " 'ཡང་དག་',\n",
       " 'ཐུགས་',\n",
       " 'སུ་',\n",
       " 'ཆུད་',\n",
       " 'རྒྱལ་བ་',\n",
       " 'ཉིས་་',\n",
       " 'ར་',\n",
       " 'གྱུར་',\n",
       " 'ལ་',\n",
       " 'གསོལ་བ་',\n",
       " 'འདེབས་',\n",
       " 'རྒྱལ་བ་',\n",
       " 'འི་',\n",
       " 'མདུན་',\n",
       " 'ན་',\n",
       " 'རྒྱལ་སྲས་',\n",
       " 'བཟང་པོ་',\n",
       " 'སྐྱོང་',\n",
       " 'ཁ་བ་',\n",
       " 'ཅན་',\n",
       " 'དུ་',\n",
       " 'དཔལ་ལྡན་',\n",
       " 'སྨ་ར་',\n",
       " 'མེ་',\n",
       " 'མཇད་',\n",
       " 'དགའ་ལྡན་',\n",
       " 'གནས་',\n",
       " 'སུ་',\n",
       " 'ནམ་མཁའ་',\n",
       " 'ཏྲི་',\n",
       " 'མ་',\n",
       " 'མེད་',\n",
       " 'ཡིད་བཞིན་',\n",
       " 'ནོར་བུ་',\n",
       " 'ཁྱེད་',\n",
       " 'ལ་',\n",
       " 'གསོལ་བ་',\n",
       " 'འདེབས་',\n",
       " 'སྒྲོལ་མ་',\n",
       " 'ས་',\n",
       " 'ལུང་བསྟན་',\n",
       " 'རྒྱལ་བུ་',\n",
       " 'དཀོན་མཆོག་',\n",
       " 'འབང་',\n",
       " 'ཐུབ་བསྟན་',\n",
       " 'ཡོངས་སུ་',\n",
       " 'རྫོགས་པ་',\n",
       " 'འི་',\n",
       " 'མངའ་བདག་',\n",
       " 'མཆོག་',\n",
       " 'ལྷ་ཆོས་',\n",
       " 'བདུན་',\n",
       " 'ཇོ་བོ་',\n",
       " 'བཀ་']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(files[i].read_text()[:500]), files[i]\n",
    "tokenize(files[i].read_text()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84459d0-1216-4faa-94e8-c049d4cb48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/botok/textunits/bostring.py:82: UserWarning: Beware of unexpected results: input string contains the non-expanded char \"ༀ\", found in \"\".\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = list(get_sentences(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e6cc8-c44a-48a6-873a-6bff5797903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244be62-70bc-41a5-8626-d952cd34f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_highest_freq_word(sentences, k=10):\n",
    "    word_freq = defaultdict(int)\n",
    "    for sent in sentences:\n",
    "        for i in sent:\n",
    "            word_freq[i] += 1\n",
    "    return sorted(word_freq, key=word_freq.get, reverse=True)[:10]\n",
    "\n",
    "top_k_highest_freq_word(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fac5e-fdd9-4733-8eb6-758e0f1d1b93",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e315a9-4a3d-4d9d-a241-3d5d73e32acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sentences, model_name, epochs=30, checkpoint=None):\n",
    "    \n",
    "    # create the model\n",
    "    model = Word2Vec(\n",
    "        vector_size=100,\n",
    "        window=5,\n",
    "        min_count=1,\n",
    "        min_alpha=0.0007, \n",
    "        negative=20,\n",
    "        workers=multiprocessing.cpu_count()-1\n",
    "    )\n",
    "    \n",
    "    # build Vocab\n",
    "    t = time()\n",
    "    model.build_vocab(sentences, progress_per=10000)\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    \n",
    "    # start training\n",
    "    t = time()\n",
    "    model.train(sentences, total_examples=model.corpus_count, epochs=epochs, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    \n",
    "    # surfix model with timestemp\n",
    "    model_name = f\"{model_name}-{datetime.now()}\"\n",
    " \n",
    "    # save the model\n",
    "    models_path = config.MODELS_DIR / \"word2vec\"\n",
    "    models_path.mkdir(exist_ok=True, parents=True)\n",
    "    model_path = models_path / f\"{model_name}.model\"\n",
    "    \n",
    "    model.save(str(model_path))\n",
    "    print(f\"[INFO] Model save at {model_path}\")\n",
    "    \n",
    "    # save only wordvectors\n",
    "    word_vectors_path = models_path / f\"{model_name}.wordvectors\"\n",
    "    \n",
    "    # Store just the words + their trained embeddings.\n",
    "    word_vectors = model.wv\n",
    "    word_vectors.save(str(word_vectors_path))\n",
    "    \n",
    "    return word_vectors_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2639f53-5cce-40a8-9a34-0ae8d7b778a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_path = train(sentences, \"literary_bo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a64142-e30a-49f6-9458-ae3e29d33977",
   "metadata": {},
   "source": [
    "## Exploring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f6ef0-3440-44bc-bea9-b0690bb5c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(str(word_vectors_path), mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711f47f-7a7f-4fb6-b7c6-10ad77c5fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"སྟོབས་\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53a172-a755-475f-a52e-632a462fd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"མཛད་པ་\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3675e-8989-4f4b-86e0-c427f0e398fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"བླ་མ་\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0424333-36a7-4827-8d01-608c7bee557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"རྩ་བ་\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86eeacb-a009-421b-bfdd-56487b26da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"ཉིད་\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39ec5f-4cc2-4c7c-85c4-107754800380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
